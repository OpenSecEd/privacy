\title{Differential Privacy}
\subtitle{An short introduction}
\author[D. Bosk <dbosk@kth.se>]{Daniel Bosk}
\institute[KTH CSC]{%
  School of Computer Science and Communication\\
  KTH Royal Institute of Technology\\
  \email{dbosk@kth.se}
}
\date{12th February 2016}

\maketitle

\mode*

\begin{abstract}
  \input{abstract.tex}
\end{abstract}


\section{Differential Privacy}

\subsection{Background}

\begin{frame}
  \begin{block}{Dalenius, 1977}
    Nothing about an individual should be learnable from the database that 
    cannot be learned without access to the database.
  \end{block}

  \pause{}

  \begin{block}{Dwork, 2006\footfullcite{DifferentialPrivacy}}
    \begin{itemize}
      \item Dwork proves this is impossible.
      \item Actually you can learn things about individuals not in the 
        database.
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}
  \begin{block}{Origin: Statistical databases}
    \begin{itemize}
      \item Privacy-preserving data analysis
      \item Statistical disclosure control
      \item Inference control
      \item Privacy-preserving data-mining
      \item Private data analysis
    \end{itemize}
  \end{block}

  \pause{}

  \begin{block}{Purpose}
    Protect one entry when publishing statistics about a database.
  \end{block}
\end{frame}

\begin{frame}
  \begin{block}{Non-interactive}
    \begin{itemize}
      \item Compute and publish some statistics.
      \item Database not used further.
      \item What can we infer from the released statistics?
    \end{itemize}
  \end{block}

  \pause{}

  \begin{block}{Interactive}
    \begin{itemize}
      \item Interactively answer statistical queries about the database.
      \item Queries and/or answers may be modified by the privacy mechanism.
    \end{itemize}
  \end{block}
\end{frame}

\subsection{Definition}

\begin{frame}
  \begin{block}{The idea}
    \begin{itemize}
      \item We want to protect one entry in this database.

        \pause{}

      \item Thus we want the result to be similar with and without this entry.

        \pause{}

      \item Thus we add random noise to achieve this.
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}
  \begin{definition}[Differential privacy\footfullcite{DiffPrivSurvey}]
    \begin{itemize}
      \item Let \(K\) be a randomized function.
      \item Let \(D_1, D_2\in \ker(K)\) be datasets differing on at most one 
        element.
      \item Let \(S\subseteq \im(K)\).
      \item \(K\) is \(\epsilon\)-differentially private if and only if
        \[\Pr[K(D_1)\in S] \leq e^\epsilon \Pr[K(D_2)\in S]\]
      \item \color{red} Probability taken over coin-tosses of \(K\).
      \end{itemize}
  \end{definition}
\end{frame}

\begin{frame}
  \begin{question}
    \begin{itemize}
      \item \enquote{Probability taken over coin-tosses of \(K\).}
      \item We need to emphasize that since it could also be the 
        \enquote{probability over the differences of \(D_1, D_2\)}.
    \end{itemize}
  \end{question}
\end{frame}

\begin{frame}
  \begin{block}{Note}
    This protects a row even if the adversary knows every other row!
  \end{block}
\end{frame}

\begin{frame}
  \begin{definition}[Sensitivity]
    \begin{itemize}
      \item Let \(f\) be the true function, i.e.\ not \(K\).
      \item \(D_1, D_2\) as before.
      \item The sensitivity of \(f\) is \[
          \Delta f = \max_{D_1, D_2} || f(D_1) - f(D_2) ||_{\color{red} 1}.
        \]
    \end{itemize}
  \end{definition}

  \pause{}

  \begin{question}
    \begin{itemize}
      \item What is the meaning of {\color{red} 1}?
        \(||\vec x||_1 = \sum_{x\in \vec x} |x|\)?
      \item It's a norm, but why specify?
      \item Shouldn't the norm depend on \(\im(f)\)?
    \end{itemize}
  \end{question}
\end{frame}

\begin{frame}
  \begin{theorem}
    \begin{itemize}
      \item \(f\) as before.
      \item \(K_f\) is the mechanism adding noise to \(f\).

        \pause{}

      \item If \(K_f\) adds noise with \(\Lap(\Delta f/\epsilon)\),
        then \(K\) provides \(\epsilon\)-differential privacy.
    \end{itemize}
  \end{theorem}

  \pause{}

  \begin{proof}\relax
    [I trust Cynthia on this for now.]
  \end{proof}
\end{frame}

\begin{frame}
  \begin{block}{Consequences}
    The needed noise depends only on the sensitivity of \(f\) and \(\epsilon\).
  \end{block}

  \pause{}

  \begin{question}
    \begin{itemize}
      \item Probably the definition is chosen due to \(\Lap\) distribution.
        \begin{description}
          \item[Definition] \(\Pr[K(D_1)\in S] \leq e^\epsilon \Pr[K(D_2)\in 
              S]\)
          \item[Proof] \(\Lap(\Delta f/\epsilon)\propto e^{-|x|(\epsilon/\Delta
                f)}\)
        \end{description}
    \end{itemize}
  \end{question}
\end{frame}

\begin{frame}
  \begin{example}[Histograms]
    \begin{itemize}
      \item Histogram query with \(k\) cells.

        \pause{}

      \item Viewed as \(k\) counting queries.

        \pause{}

      \item Adding or removing a database entry can affect at most one of \(k\)
        cells.

        \pause{}

      \item Thus the histogram function has sensitivity \(1\).
    \end{itemize}
  \end{example}
\end{frame}


\section{Uses}

\subsection{Statistical databases}

\begin{frame}
  \begin{block}{The work being done}
    How to add noise to different functions?
  \end{block}

  \pause{}

  \begin{question}
    This is my interpretation of the survey.
    Agree?
  \end{question}
\end{frame}

\subsection{Matching profiles}

\begin{frame}
  \begin{block}{The idea}
    \begin{itemize}
      \item Differential privacy is designed for statistics.
      \item {\color{red} We must be able to add noise (?).}

        \pause{}

      \item Computing a similarity score can be based on statistics:
        \begin{itemize}
          \item Is item \(X\) in the database? (\(Count(X)\))
          \item That's a statistical question.
        \end{itemize}
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}
  \begin{example}[Standard use]
    \begin{itemize}
      \item Have a statistical database.
      \item Each user's data corresponds to one row.

        \pause{}

      \item We protect individual users, by protecting the rows.
    \end{itemize}
  \end{example}

  \pause{}

  \begin{example}[BLIP\footfullcite{BLIP-2}]
    \begin{itemize}
      \item Let a user profile be the database.
        \begin{itemize}
          \item Each row is a \enquote{like}.
          \item Or a photo or a comment.
        \end{itemize}

        \pause{}

      \item Protect the individual rows.
        \begin{itemize}
          \item Protect the contents of the profile.
        \end{itemize}
    \end{itemize}
  \end{example}
\end{frame}

\begin{frame}
  \begin{block}{BLoom-and-flIP, BLIP}
    \begin{itemize}
      \item Hash the entries of the profile into a Bloom filter (\(L\)-bit 
        string).

        \pause{}

      \item Generate a random \(L\)-bit string.
      \item XOR them together --- adds noise.
    \end{itemize}
  \end{block}

  \pause{}

  \begin{block}{Results\footfullcite{BLIP-2}}
    \begin{itemize}
      \item BLIP is \(\epsilon\)-differentially private.
      \item So you can do reconstruction \enquote{within \(\epsilon\)}.
    \end{itemize}
  \end{block}
\end{frame}


\section{Problems}

\subsection{Attacks?}

\begin{frame}
  \begin{block}{Isn't it a guarantee?}
    \begin{itemize}
      \item You are guaranteed \(\epsilon\)-differential privacy.
      \item So there is something the attacker may learn.

        \pause{}

      \item But how much is that?
      \item How do we choose \(\epsilon\)?
    \end{itemize}
  \end{block}

  \pause{}

  \begin{block}{Setting \(\epsilon\)}
    \begin{itemize}
      \item That's an open research problem~\cite{ChallengingDiffPriv}.
    \end{itemize}
  \end{block}

\end{frame}

\begin{frame}
  \begin{block}{Practical attacks\footfullcite{ChallengingDiffPriv}}
    \begin{itemize}
      \item \citet{ChallengingDiffPriv} constructs two practical attacks.
      \item These reconstruct the profiles in BLIP (within \(\epsilon\)).

        \pause{}

      \item This is one step closer to an informed choice for \(\epsilon\).
    \end{itemize}
  \end{block}
\end{frame}

\subsection{Outline of attack}

\begin{frame}
\end{frame}


\section{Discussion}

\subsection{Comments}

\begin{frame}
  \begin{question}
    \begin{itemize}
      \item The original paper has more than 1500 citations.
      \item That suggests a lot of results in the area.

        \pause{}

      \item Considering that, isn't the survey a bit shallow?
    \end{itemize}
  \end{question}
\end{frame}

\begin{frame}
  \begin{block}{Recommended reading}
    \begin{itemize}
      \item \fullcite{ChallengingDiffPriv}
    \end{itemize}
  \end{block}
\end{frame}

\subsection{Questions}

\begin{frame}
  \begin{question}
    Must we add noise?
    Apparently not\footfullcite{MechanismDesignViaDiffPriv}.
  \end{question}

  \pause{}

  \begin{example}
    \begin{itemize}
      \item In their work \(f\) maps databases to strings, strategies or trees.

        \pause{}

      \item Well, it's kind of the case for BLIP, isn't it?
      \item But BLIP still adds noise.

        \pause{}

      \item They use a utility function \(u(D, y)\) measuring the quality of 
        \(y\).

      \item They output a \(y\) with probability \(e^{-\epsilon u(D,y)/2}\).
    \end{itemize}
  \end{example}

  \pause{}

  \begin{question}
    Isn't this just a matter of perspective?
  \end{question}
\end{frame}

\begin{frame}
  \begin{question}
    \begin{itemize}
      \item Can we use differential privacy also when presenting our profile?
      \item I add random noise to my profile?
      \item I randomly remove entries?
    \end{itemize}
  \end{question}

  \pause{}

  \begin{question}
    \begin{itemize}
      \item What else can we use it for?
      \item Is the addition of noise a sufficient criteria?
    \end{itemize}
  \end{question}
\end{frame}

\begin{frame}
  \begin{question}
    Any other thoughts, comments or questions?
  \end{question}
\end{frame}


%%% REFERENCES %%%

\begin{frame}[allowframebreaks]
  \printbibliography{}
\end{frame}
